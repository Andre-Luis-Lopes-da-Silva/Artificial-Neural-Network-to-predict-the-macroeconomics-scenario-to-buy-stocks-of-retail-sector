{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a49579ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"/home/andre/Desktop/projeto Renner/dataset_b.csv\")\n",
    "# https://iaexpert.academy/2020/05/04/quantas-camadas-escondidas-e-quantos-neuronios-incluir-numa-rede-neural-artificial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "398b6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73477c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0eea49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['IBC-Br'] = [float(str(i).replace(\",\", \".\")) for i in dataset['IBC-Br']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "674171f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      132.66\n",
       "1      136.18\n",
       "2      144.93\n",
       "3      139.89\n",
       "4      143.23\n",
       "        ...  \n",
       "127    142.05\n",
       "128    138.96\n",
       "129    138.46\n",
       "130    140.22\n",
       "131    141.96\n",
       "Name: IBC-Br, Length: 132, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['IBC-Br']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3b7ffc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c81f2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.drop(0) # tira a linha 0 \n",
    "new_data_set = dataset.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "981ec9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend</th>\n",
       "      <th>ipca</th>\n",
       "      <th>selic</th>\n",
       "      <th>IBC-Br</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uptrend</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10.943548</td>\n",
       "      <td>132.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uptrend</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>136.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uptrend</td>\n",
       "      <td>0.79</td>\n",
       "      <td>11.717742</td>\n",
       "      <td>144.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uptrend</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>139.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uptrend</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>143.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trend  ipca      selic  IBC-Br\n",
       "0  Uptrend  0.83  10.943548  132.66\n",
       "1  Uptrend  0.80  11.250000  136.18\n",
       "2  Uptrend  0.79  11.717742  144.93\n",
       "3  Uptrend  0.77  11.800000  139.89\n",
       "4  Uptrend  0.47  12.000000  143.23"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8f78549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d84eca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labelencoder.fit_transform(new_data_set['trend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ee5d95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49650ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = new_data_set.drop(['trend'], axis = 1)\n",
    "X = previsores.iloc[:,0:132].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "76a5b87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99, 3),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "X_train.shape, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8498cd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33, 3),\n",
       " array([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9490d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape é igual ao número de atributos\n",
    "# o erro que dava é porque estava tentando usar a activation = 'softmax', quando coloquei a sigmoid deu certo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5c492204",
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural = tf.keras.models.Sequential()\n",
    "rede_neural.add(tf.keras.layers.Dense(units = 3, activation='relu', input_shape=(3,)))\n",
    "rede_neural.add(tf.keras.layers.Dense(units = 3, activation = 'relu'))\n",
    "rede_neural.add(tf.keras.layers.Dense(units = 3, activation = 'relu'))\n",
    "rede_neural.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e437124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rede_neural.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3b7a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural.compile(optimizer='Adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c92dc17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.6667\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.8485\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.8485\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.8485\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.8485\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.8485\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.8485\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.8485\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6825 - accuracy: 0.8485\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6812 - accuracy: 0.8485\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6799 - accuracy: 0.8485\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6786 - accuracy: 0.8485\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.8485\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.8485\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6749 - accuracy: 0.8485\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6736 - accuracy: 0.8485\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.8485\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6710 - accuracy: 0.8485\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6697 - accuracy: 0.8485\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6683 - accuracy: 0.8485\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6672 - accuracy: 0.8485\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6658 - accuracy: 0.8485\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6646 - accuracy: 0.8485\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6633 - accuracy: 0.8485\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6620 - accuracy: 0.8485\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6608 - accuracy: 0.8485\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.8485\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6584 - accuracy: 0.8485\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6572 - accuracy: 0.8485\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6560 - accuracy: 0.8485\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.8485\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6537 - accuracy: 0.8485\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6525 - accuracy: 0.8485\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6513 - accuracy: 0.8485\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6502 - accuracy: 0.8485\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.8485\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.8485\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.8485\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.8485\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.8485\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.8485\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.8485\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6406 - accuracy: 0.8485\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6395 - accuracy: 0.8485\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.8485\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6372 - accuracy: 0.8485\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.8485\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6350 - accuracy: 0.8485\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6339 - accuracy: 0.8485\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.8485\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.8485\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6307 - accuracy: 0.8485\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.8485\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.8485\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6275 - accuracy: 0.8485\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6264 - accuracy: 0.8485\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6254 - accuracy: 0.8485\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.8485\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.8485\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.8485\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.8485\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6205 - accuracy: 0.8485\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.8485\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.8485\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6174 - accuracy: 0.8485\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.8485\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.8485\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.8485\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6134 - accuracy: 0.8485\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6125 - accuracy: 0.8485\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.8485\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6107 - accuracy: 0.8485\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.8485\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6090 - accuracy: 0.8485\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.8485\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.8485\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.8485\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.8485\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.8485\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.8485\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.8485\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.8485\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.8485\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5999 - accuracy: 0.8485\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5990 - accuracy: 0.8485\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.8485\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.8485\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.8485\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.8485\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.8485\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5935 - accuracy: 0.8485\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.8485\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.8485\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5909 - accuracy: 0.8485\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5900 - accuracy: 0.8485\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.8485\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.8485\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.8485\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.8485\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5857 - accuracy: 0.8485\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.8485\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.8485\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.8485\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.8485\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.8485\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.8485\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.8485\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.8485\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.8485\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.8485\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5766 - accuracy: 0.8485\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.8485\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.8485\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5744 - accuracy: 0.8485\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.8485\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.8485\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.8485\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.8485\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.8485\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.8485\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.8485\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.8485\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.8485\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5666 - accuracy: 0.8485\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5658 - accuracy: 0.8485\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.8485\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.8485\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.8485\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5625 - accuracy: 0.8485\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.8485\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.8485\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.8485\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.8485\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.8485\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.8485\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.8485\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.8485\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.8485\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.8485\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.8485\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.8485\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.8485\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.8485\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.8485\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.8485\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.8485\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.8485\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5489 - accuracy: 0.8485\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.8485\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.8485\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.8485\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.8485\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.8485\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.8485\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.8485\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.8485\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.8485\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.8485\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.8485\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8485\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.8485\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.8485\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.8485\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.8485\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.8485\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.8485\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.8485\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.8485\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.8485\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.8485\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.8485\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.8485\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.8485\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.8485\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.8485\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.8485\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.8485\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.8485\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.8485\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.8485\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5283 - accuracy: 0.8485\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.8485\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.8485\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.8485\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.8485\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.8485\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.8485\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.8485\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.8485\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.8485\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.8485\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.8485\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.8485\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.8485\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.8485\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.8485\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.8485\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.8485\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.8485\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f65b47bdeb0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rede_neural.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07a63075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.80000000e-01,  1.17016129e+01,  1.45480000e+02],\n",
       "       [ 5.90000000e-01,  7.33064516e+00,  1.47710000e+02],\n",
       "       [ 1.30000000e-01,  6.50000000e+00,  1.39400000e+02],\n",
       "       [ 1.00000000e-02,  1.10000000e+01,  1.49850000e+02],\n",
       "       [ 4.80000000e-01,  6.50000000e+00,  1.35770000e+02],\n",
       "       [ 7.90000000e-01,  1.37000000e+01,  1.38530000e+02],\n",
       "       [ 1.50000000e-01,  1.21833333e+01,  1.41750000e+02],\n",
       "       [ 5.30000000e-01,  3.85000000e+00,  1.37780000e+02],\n",
       "       [ 4.30000000e-01,  8.17741935e+00,  1.47460000e+02],\n",
       "       [ 3.60000000e-01,  8.98387097e+00,  1.44560000e+02],\n",
       "       [ 4.60000000e-01,  1.10000000e+01,  1.47140000e+02],\n",
       "       [ 3.80000000e-01,  1.32661290e+01,  1.28470000e+02],\n",
       "       [ 5.30000000e-01,  1.20000000e+01,  1.42300000e+02],\n",
       "       [ 6.40000000e-01,  2.00000000e+00,  1.37120000e+02],\n",
       "       [ 2.20000000e-01,  6.50000000e+00,  1.39080000e+02],\n",
       "       [ 2.40000000e-01,  2.04032258e+00,  1.35650000e+02],\n",
       "       [ 7.30000000e-01,  8.86290323e+00,  1.41960000e+02],\n",
       "       [ 7.70000000e-01,  1.18000000e+01,  1.39890000e+02],\n",
       "       [-2.10000000e-01,  6.50000000e+00,  1.37660000e+02],\n",
       "       [ 7.10000000e-01,  1.27666667e+01,  1.42420000e+02],\n",
       "       [ 8.00000000e-02,  1.42500000e+01,  1.33870000e+02],\n",
       "       [ 4.20000000e-01,  1.10161290e+01,  1.49700000e+02],\n",
       "       [ 8.90000000e-01,  2.00000000e+00,  1.38160000e+02],\n",
       "       [ 1.60000000e-01,  1.23387097e+01,  1.45190000e+02],\n",
       "       [ 6.40000000e-01,  9.45000000e+00,  1.39850000e+02],\n",
       "       [ 5.10000000e-01,  5.00000000e+00,  1.38870000e+02],\n",
       "       [ 2.60000000e-01,  2.67500000e+03,  1.25830000e+02],\n",
       "       [ 7.40000000e-01,  1.32500000e+01,  1.39810000e+02],\n",
       "       [ 1.32000000e+00,  1.26854839e+01,  1.49500000e+02],\n",
       "       [ 9.20000000e-01,  1.00000000e+01,  1.45770000e+02],\n",
       "       [ 2.50000000e-01,  2.00000000e+00,  1.31590000e+02],\n",
       "       [ 5.10000000e-01,  1.12500000e+01,  1.44920000e+02],\n",
       "       [ 5.40000000e-01,  1.42500000e+01,  1.38060000e+02],\n",
       "       [ 5.70000000e-01,  7.50000000e+00,  1.41600000e+02],\n",
       "       [ 5.50000000e-01,  7.35833333e+00,  1.49790000e+02],\n",
       "       [ 6.00000000e-01,  7.25000000e+00,  1.36140000e+02],\n",
       "       [ 1.90000000e-01,  9.25000000e+00,  1.40140000e+02],\n",
       "       [ 5.60000000e-01,  1.07903226e+01,  1.33340000e+02],\n",
       "       [ 1.50000000e-01,  6.50000000e+00,  1.36330000e+02],\n",
       "       [ 1.27000000e+00,  1.42500000e+01,  1.28250000e+02],\n",
       "       [ 9.20000000e-01,  1.07500000e+01,  1.49030000e+02],\n",
       "       [ 3.30000000e-01,  6.50000000e+00,  1.41060000e+02],\n",
       "       [-3.10000000e-01,  3.75000000e+00,  1.18350000e+02],\n",
       "       [ 2.50000000e-01,  1.22500000e+01,  1.41900000e+02],\n",
       "       [ 1.24000000e+00,  1.19112903e+01,  1.38730000e+02],\n",
       "       [ 3.00000000e-01,  1.37500000e+01,  1.33340000e+02],\n",
       "       [ 2.40000000e-01,  1.00887097e+01,  1.38420000e+02],\n",
       "       [ 1.00000000e-02,  6.50000000e+00,  1.35120000e+02],\n",
       "       [ 5.50000000e-01,  1.02580645e+01,  1.42720000e+02],\n",
       "       [ 8.60000000e-01,  7.25000000e+00,  1.39320000e+02],\n",
       "       [ 1.40000000e-01,  1.16500000e+01,  1.33750000e+02],\n",
       "       [ 5.70000000e-01,  1.10000000e+01,  1.48120000e+02],\n",
       "       [ 9.60000000e-01,  1.42500000e+01,  1.36220000e+02],\n",
       "       [ 1.00000000e-01,  5.48387097e+00,  1.42940000e+02],\n",
       "       [-4.00000000e-02,  5.80000000e+00,  1.38330000e+02],\n",
       "       [ 2.50000000e-01,  1.10000000e+01,  1.48270000e+02],\n",
       "       [ 3.60000000e-01,  2.25000000e+00,  1.35840000e+02],\n",
       "       [ 5.70000000e-01,  6.50000000e+00,  1.39690000e+02],\n",
       "       [ 1.60000000e-01,  8.48333333e+00,  1.34850000e+02],\n",
       "       [ 1.15000000e+00,  4.67741935e+00,  1.37420000e+02],\n",
       "       [ 3.10000000e-01,  2.75000000e+00,  1.38600000e+02],\n",
       "       [ 3.50000000e-01,  9.00000000e+00,  1.47270000e+02],\n",
       "       [ 4.70000000e-01,  1.20000000e+01,  1.43230000e+02],\n",
       "       [ 4.30000000e-01,  1.18064516e+01,  1.42020000e+02],\n",
       "       [ 3.70000000e-01,  7.53225806e+00,  1.47030000e+02],\n",
       "       [ 6.70000000e-01,  1.09833333e+01,  1.47690000e+02],\n",
       "       [ 2.90000000e-01,  7.00000000e+00,  1.32110000e+02],\n",
       "       [ 5.40000000e-01,  9.55000000e+00,  1.47790000e+02],\n",
       "       [ 8.60000000e-01,  2.00000000e+00,  1.39830000e+02],\n",
       "       [ 1.25000000e+00,  6.44354839e+00,  1.38460000e+02],\n",
       "       [ 7.80000000e-01,  1.42500000e+01,  1.33540000e+02],\n",
       "       [ 3.10000000e-01,  1.12500000e+01,  1.35990000e+02],\n",
       "       [ 7.90000000e-01,  7.25000000e+00,  1.39520000e+02],\n",
       "       [ 2.50000000e-01,  4.29310345e+00,  1.34380000e+02],\n",
       "       [-9.00000000e-02,  6.50000000e+00,  1.43420000e+02],\n",
       "       [ 2.40000000e-01,  8.54838710e+00,  1.51810000e+02],\n",
       "       [ 4.70000000e-01,  7.25000000e+00,  1.48010000e+02],\n",
       "       [ 4.00000000e-01,  1.10000000e+01,  1.40880000e+02],\n",
       "       [ 2.20000000e-01,  1.42500000e+01,  1.40830000e+02],\n",
       "       [ 5.20000000e-01,  1.42500000e+01,  1.36720000e+02],\n",
       "       [ 3.50000000e-01,  1.42500000e+01,  1.35270000e+02],\n",
       "       [ 3.30000000e-01,  1.28392857e+01,  1.29390000e+02],\n",
       "       [ 4.50000000e-01,  6.50000000e+00,  1.39840000e+02],\n",
       "       [ 2.10000000e-01,  4.50000000e+00,  1.33940000e+02],\n",
       "       [ 2.10000000e-01,  9.91935484e+00,  1.46350000e+02],\n",
       "       [ 1.26000000e+00,  6.50000000e+00,  1.36950000e+02],\n",
       "       [ 1.80000000e-01,  1.40000000e+01,  1.32370000e+02],\n",
       "       [ 6.20000000e-01,  1.37822581e+01,  1.43130000e+02],\n",
       "       [ 2.60000000e-01,  8.00000000e+00,  1.44870000e+02],\n",
       "       [ 1.10000000e-01,  6.00000000e+00,  1.41940000e+02],\n",
       "       [ 7.50000000e-01,  6.50000000e+00,  1.39040000e+02],\n",
       "       [ 4.20000000e-01,  8.10483871e+00,  1.36060000e+02],\n",
       "       [ 3.20000000e-01,  6.50000000e+00,  1.33580000e+02],\n",
       "       [ 1.90000000e-01,  6.50000000e+00,  1.43150000e+02],\n",
       "       [ 9.00000000e-02,  6.66935484e+00,  1.41560000e+02],\n",
       "       [ 2.60000000e-01,  1.41532258e+01,  1.32720000e+02],\n",
       "       [ 8.30000000e-01,  1.09435484e+01,  1.32660000e+02],\n",
       "       [ 7.00000000e-02,  4.04032258e+00,  1.36040000e+02],\n",
       "       [-3.80000000e-01,  3.14516129e+00,  1.19450000e+02]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "455ecc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416],\n",
       "       [0.6577416]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rede_neural.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f89a420e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred >= 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e0517fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8],\n",
       "       [ 0, 25]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "677c4c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "43d830ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.76      1.00      0.86        25\n",
      "\n",
      "    accuracy                           0.76        33\n",
      "   macro avg       0.38      0.50      0.43        33\n",
      "weighted avg       0.57      0.76      0.65        33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andre/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/andre/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a8d60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considerando tendẽncia de alta mesmo com correções, mas levando em consideração os fundos e topos ascendentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db056ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
